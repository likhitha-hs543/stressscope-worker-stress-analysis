# ğŸ§  StressScope - Worker Stress Analysis System

**Real-time multimodal AI system for workplace stress detection**

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## ğŸ¯ What It Does

StressScope combines **facial emotion recognition** and **speech stress analysis** to provide real-time, privacy-preserving workplace stress detection.

**Key Features:**
- ğŸ­ Facial emotion recognition (MobileNetV2, 50.17% accuracy)
- ğŸ¤ Speech stress detection (Ensemble, 69.91% accuracy)  
- ğŸ”€ Multimodal fusion (~60% combined accuracy)
- ğŸ“Š Dual dashboards (employee self-awareness + admin analytics)
- ğŸ”’ Privacy-first design (no raw media storage)

---

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Initialize database
python setup.py

# Run application
python app.py
```

Visit: **http://localhost:5000**

ğŸ“˜ **Full Setup Guide:** See [docs/User_Guide.md](docs/User_Guide.md)

---

## ğŸ“Š System Performance

| Component | Accuracy | Method |
|-----------|----------|--------|
| **Facial v2** | 50.17% | MobileNetV2 (transfer learning) |
| **Speech v1** | 69.91% | Ensemble (Random Forest + GB) |
| **Fusion** | ~60% | Weighted (60% speech, 40% facial) |

**Improvement:** Facial v1 (13.21%) â†’ v2 (50.17%) = **+36.96pp** through transfer learning

---

## ğŸ—ï¸ Architecture

```
Webcam + Microphone
        â†“
Facial (MobileNetV2) + Speech (Ensemble)
        â†“
Multimodal Fusion (60/40)
        â†“
Rules Engine (alerts + recommendations)
        â†“
Dashboard (employee + admin)
```

ğŸ›ï¸ **Technical Details:** See [docs/Design_and_Implementation.md](docs/Design_and_Implementation.md)

---

## ğŸ“ Project Structure

```
worker stress analysis/
â”œâ”€â”€ app.py                          # Flask API backend
â”œâ”€â”€ config.py                       # Configuration
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ modules/                        # Core AI modules
â”‚   â”œâ”€â”€ facial_recognition.py      # MobileNetV2 facial analysis
â”‚   â”œâ”€â”€ speech_recognition.py      # Ensemble speech analysis
â”‚   â”œâ”€â”€ multimodal_fusion.py       # Fusion engine
â”‚   â””â”€â”€ rules_engine.py             # Business logic
â”œâ”€â”€ templates/                      # Frontend dashboard
â”œâ”€â”€ models/trained/                 # Saved models (.keras, .pkl)
â”œâ”€â”€ train_facial_mobilenetv2.py    # Facial training script
â”œâ”€â”€ train_speech_from_ravdess.py   # Speech training script
â””â”€â”€ docs/                           # Documentation
    â”œâ”€â”€ User_Guide.md               # Setup & usage
    â””â”€â”€ Design_and_Implementation.md# Architecture & methodology
```

---

## ğŸ“ Training Models

### Facial Model (Transfer Learning)
```bash
python train_facial_mobilenetv2.py --data-dir "data/face/FER 2013" --phase1-epochs 15 --phase2-epochs 10
```

### Speech Model (Ensemble)
```bash
python prepare_ravdess_data.py --input-dir "data/speech/SER/Ravdess"
python train_speech_from_ravdess.py --data-dir "data/speech/SER/prepared"
```

ğŸ“Š **Training Details:** See [TRAINING_STATUS.md](TRAINING_STATUS.md)

---

##Privacy & Ethics

**What's Stored:**
- âœ… Aggregated stress scores + timestamps
- âœ… Session metadata

**What's NOT Stored:**
- âŒ Raw video/audio
- âŒ Facial images
- âŒ Individual PII (in admin view)

**Purpose:** Self-awareness tool, not surveillance or diagnosis

---

## ğŸ“š Documentation

- ğŸ“˜ **[User Guide](docs/User_Guide.md)** - Installation, setup, troubleshooting
- ğŸ›ï¸ **[Design & Implementation](docs/Design_and_Implementation.md)** - Architecture, methodology, viva defense
- ğŸ“Š **[Training Status](TRAINING_STATUS.md)** - Model versions, performance comparison
- ğŸ“¡ **[API Documentation](API_DOCUMENTATION.md)** - Complete API reference

---

## ğŸ¤ Academic Context

**This project demonstrates:**
- Complete ML pipeline (baseline â†’ improvement â†’ deployment)
- Transfer learning applied correctly
- Systematic iteration (+36.96pp improvement)
- Privacy-preserving multimodal AI
- Production-ready system design

**Suitable for:** Final year projects, ML coursework, research demonstrations

---

## ğŸ“„ License

MIT License - Free for educational and research purposes.

**Disclaimer:** This system is for research and self-awareness only. Not a medical device.

---

## ğŸ‘¨â€ğŸ’» Author

Built to demonstrate professional ML engineering and multimodal system design.

**GitHub:** [likhitha-hs543/stressscope-worker-stress-analysis](https://github.com/likhitha-hs543/stressscope-worker-stress-analysis)

---

**Status:** âœ… Production Ready | ğŸ“Š ~60% Multimodal Accuracy | ğŸ”’ Privacy-First Design
